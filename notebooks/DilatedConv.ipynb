{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, Conv1D, Dropout, LSTM, BatchNormalization, Input,Activation, MaxPool2D, Flatten \n",
    "from keras.layers import Dense,TimeDistributed, Lambda\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "from keras import metrics\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import h5py\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['006',\n",
       "  '017',\n",
       "  '003',\n",
       "  '016',\n",
       "  '009',\n",
       "  '013',\n",
       "  '005',\n",
       "  '012',\n",
       "  '010',\n",
       "  '015',\n",
       "  '014',\n",
       "  '007',\n",
       "  '004',\n",
       "  '011',\n",
       "  '002',\n",
       "  '001'],\n",
       " ['006', '003', '009', '005', '010', '007', '004', '002', '008', '001'],\n",
       " ['006', '009', '005', '010', '007', '004', '002', '008', '001'],\n",
       " ['006', '003', '009', '005', '010', '007', '004', '002', '008', '001'],\n",
       " ['006',\n",
       "  '017',\n",
       "  '003',\n",
       "  '016',\n",
       "  '009',\n",
       "  '013',\n",
       "  '005',\n",
       "  '012',\n",
       "  '010',\n",
       "  '015',\n",
       "  '014',\n",
       "  '007',\n",
       "  '004',\n",
       "  '011',\n",
       "  '002',\n",
       "  '008',\n",
       "  '001'],\n",
       " ['003', '005', '004', '002', '001'],\n",
       " ['006', '003', '009', '005', '010', '007', '004', '011', '002', '008', '001'],\n",
       " ['006',\n",
       "  '017',\n",
       "  '003',\n",
       "  '016',\n",
       "  '009',\n",
       "  '013',\n",
       "  '005',\n",
       "  '012',\n",
       "  '010',\n",
       "  '015',\n",
       "  '014',\n",
       "  '007',\n",
       "  '019',\n",
       "  '004',\n",
       "  '011',\n",
       "  '018',\n",
       "  '002',\n",
       "  '008',\n",
       "  '001'],\n",
       " ['006',\n",
       "  '003',\n",
       "  '009',\n",
       "  '013',\n",
       "  '005',\n",
       "  '012',\n",
       "  '010',\n",
       "  '014',\n",
       "  '007',\n",
       "  '004',\n",
       "  '011',\n",
       "  '002',\n",
       "  '008',\n",
       "  '001']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VIDEOS_DIR = '../Videos/'\n",
    "IMAGES_DIR = '../Images/'\n",
    "classes = []\n",
    "class_to_index = {}\n",
    "videos = []\n",
    "\n",
    "classes = ['Kicking', 'Riding-Horse', 'Running', 'SkateBoarding', 'Swing-Bench', 'Lifting', 'Swing-Side', 'Walking', 'Golf-Swing']\n",
    "\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    class_to_index[classes[i]] = i\n",
    "class_to_index\n",
    "\n",
    "for x in classes:\n",
    "    videos.append(list(os.listdir(VIDEOS_DIR+x+'/')))\n",
    "videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permute(X,Y):\n",
    "    train_size = X.shape[0]\n",
    "    permutation_train = np.random.permutation(train_size)\n",
    "    X = X[permutation_train]\n",
    "    Y = Y[permutation_train]\n",
    "    return X,Y\n",
    "\n",
    "def load_image(path,image_size):\n",
    "    image = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, image_size)\n",
    "    return image\n",
    "\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)]\n",
    "    return Y\n",
    "\n",
    "def pad(X_train_images_class,max_len):\n",
    "    length = len(X_train_images_class)\n",
    "    pad_arr = np.zeros((X_train_images_class.shape[1:4]),dtype=np.uint8)\n",
    "    X_train_images_class = list(X_train_images_class)\n",
    "    for i in range(max_len-length):\n",
    "        X_train_images_class.append(pad_arr)\n",
    "    return np.array(X_train_images_class,dtype=np.uint8)\n",
    "\n",
    "def predict(model,X,verbose=True):\n",
    "    pred = model.predict(X)[0]\n",
    "    max_pred = [np.argmax(i) for i in pred]\n",
    "    if verbose:\n",
    "        print(\"Max Preds time\", max_pred)\n",
    "    counts = np.bincount(max_pred)\n",
    "    class_pred = np.argmax(counts)\n",
    "    return class_pred\n",
    "\n",
    "def evaluate(model, X_test,Y_test,verbose = True):\n",
    "    count = 0\n",
    "    preds = []\n",
    "    for i in range(len(X_test)):\n",
    "        class_pred = predict(model,X_test[i],verbose=verbose)\n",
    "        preds.append(class_pred)\n",
    "        actual = Y_test[i]\n",
    "        if verbose:\n",
    "            print(\"Pred\",classes[class_pred],\"Actual\",classes[actual])\n",
    "            print()\n",
    "        if class_pred == actual:\n",
    "            count += 1\n",
    "    \n",
    "    print(\"Confusion Matrix\")\n",
    "    print(confusion_matrix(Y_test,preds))\n",
    "    return float(count)/float(len(Y_test)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilated_conv(input_shape):\n",
    "    X_input = Input(input_shape)\n",
    "    X = TimeDistributed(BatchNormalization(), name = 'BatchNorm_1')(X_input)\n",
    "    #X = TimeDistributed(ZeroPadding2D((3, 3)))(X)\n",
    "    X = TimeDistributed(Conv2D(32, (7, 7), strides = (4, 4), activation='relu', padding=\"same\"), name=\"Conv_1a\")(X)\n",
    "    X = TimeDistributed(Conv2D(32, (3, 3), activation='relu', padding=\"same\"), name=\"Conv_1b\")(X)\n",
    "    X = TimeDistributed(MaxPool2D((2, 2)), name = \"Pool_1\")(X)\n",
    "    X = TimeDistributed(Dropout(0.2), name='Dropout_a')(X)\n",
    "    \n",
    "    X = TimeDistributed(Conv2D(32, (3, 3), activation='relu', padding = \"same\"), name =\"Conv_2a\")(X)\n",
    "    #X = TimeDistributed(Conv2D(32, (3, 3), name =\"Conv_2b\", activation='relu', padding = \"same\"))(X)\n",
    "    X = TimeDistributed(MaxPool2D((2, 2)), name = \"Pool_2\")(X)\n",
    "    X = TimeDistributed(Dropout(0.2), name='Dropout_b')(X)\n",
    "    X = TimeDistributed(Conv2D(32,(3,3),activation='relu'), name='Conv_3a')(X)\n",
    "    X = TimeDistributed(MaxPool2D((2, 2)), name = \"Pool_3\")(X)\n",
    "    \n",
    "    X = TimeDistributed(Conv2D(8,(1,1),activation='relu'), name='Conv_1x1')(X)\n",
    "    X = TimeDistributed(Flatten(), name='Flatten')(X)\n",
    "    X = TimeDistributed(Dropout(0.3), name='Dropout_c')(X)\n",
    "    Y = TimeDistributed(Dense(9,activation='softmax',name='final'))(X)\n",
    "\n",
    "    X = Conv1D(64, 4, dilation_rate=2, name = 'Conv1Da', activation='relu')(X)\n",
    "    X = Conv1D(48, 3, dilation_rate=4, name = 'Conv1Db', activation='relu')(X)\n",
    "    X = Conv1D(32, 3, dilation_rate=4, name = 'Conv1Dc', activation='relu')(X)\n",
    "    X = Lambda(lambda x : x[:, -1, :], name = \"Extractoutput\")(X)\n",
    "    X = Dense(9, activation='softmax', name = 'Output')(X)\n",
    "    return Model(X_input, [X,Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    }
   ],
   "source": [
    "dcnn = dilated_conv((40, 172, 172, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 40, 172, 172, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "BatchNorm_1 (TimeDistributed)   (None, 40, 172, 172, 12          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1a (TimeDistributed)       (None, 40, 43, 43, 3 4736        BatchNorm_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1b (TimeDistributed)       (None, 40, 43, 43, 3 9248        Conv_1a[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Pool_1 (TimeDistributed)        (None, 40, 21, 21, 3 0           Conv_1b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Dropout_a (TimeDistributed)     (None, 40, 21, 21, 3 0           Pool_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Conv_2a (TimeDistributed)       (None, 40, 21, 21, 3 9248        Dropout_a[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Pool_2 (TimeDistributed)        (None, 40, 10, 10, 3 0           Conv_2a[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Dropout_b (TimeDistributed)     (None, 40, 10, 10, 3 0           Pool_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Conv_3a (TimeDistributed)       (None, 40, 8, 8, 32) 9248        Dropout_b[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Pool_3 (TimeDistributed)        (None, 40, 4, 4, 32) 0           Conv_3a[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1x1 (TimeDistributed)      (None, 40, 4, 4, 8)  264         Pool_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Flatten (TimeDistributed)       (None, 40, 128)      0           Conv_1x1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Dropout_c (TimeDistributed)     (None, 40, 128)      0           Flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv1Da (Conv1D)                (None, 34, 64)       32832       Dropout_c[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Conv1Db (Conv1D)                (None, 26, 48)       9264        Conv1Da[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv1Dc (Conv1D)                (None, 18, 32)       4640        Conv1Db[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Extractoutput (Lambda)          (None, 32)           0           Conv1Dc[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Output (Dense)                  (None, 9)            297         Extractoutput[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 40, 9)        1161        Dropout_c[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 80,950\n",
      "Trainable params: 80,944\n",
      "Non-trainable params: 6\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dcnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcnn.compile(loss=['categorical_crossentropy', 'categorical_crossentropy'], loss_weights=[1, 0.6],\n",
    "        metrics=['accuracy'],\n",
    "        optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset_end_to_end(image_size, max_len = 40, stride = 10):\n",
    "    \n",
    "    X_train_images = []\n",
    "    Y_train_images = []\n",
    "    \n",
    "    X_test_images = []\n",
    "    Y_test_images = []\n",
    "    \n",
    "    test_videos = [['004', '011', '007'], ['006', '010'], ['007', '002'], \\\n",
    "                   ['003','001'], ['006', '012', '009'], ['004', '005'], ['008','002'], ['004', '012', '002'], ['001', '013', '006']]\n",
    "    \n",
    "    for i in range(len(classes)):\n",
    "        cls = classes[i]\n",
    "        test = test_videos[i] \n",
    "        for j in range(len(videos[i])):\n",
    "            vid = videos[i][j]\n",
    "            video_r = VIDEOS_DIR+cls+'/'+ vid +'/'\n",
    "            image_r = IMAGES_DIR+cls+'/'+ vid +'/'\n",
    "            filelist = sorted(list(os.listdir(image_r)))\n",
    "            X_train_images_class = []\n",
    "            for file in filelist:\n",
    "                if file.endswith(\".png\"):\n",
    "                    image = load_image(image_r+file,image_size)\n",
    "                    X_train_images_class.append(image)\n",
    "            X_train_images_class = np.array(X_train_images_class)        \n",
    "            X_test_frames = []                                \n",
    "            for k in range(0,len(X_train_images_class),stride):\n",
    "                lower = k\n",
    "                upper = min(len(X_train_images_class),k+max_len)\n",
    "                if upper == len(X_train_images_class):\n",
    "                    if vid not in test:                \n",
    "                        X_train_images.append(pad(X_train_images_class[lower:upper],max_len))\n",
    "                        Y_train_images.append(i)\n",
    "                    else:\n",
    "                        print(\"Test Vid\" ,vid)\n",
    "                        X_test_frames.append(pad(X_train_images_class[lower:upper],max_len))\n",
    "                        X_test_images.append(np.array(X_test_frames))        \n",
    "                        Y_test_images.append(i)\n",
    "                    #print(\"Padded frames\" , lower , \"to\" , upper)\n",
    "                    break\n",
    "                else:\n",
    "                    if vid not in test:                \n",
    "                        X_train_images.append(X_train_images_class[lower:upper])\n",
    "                        Y_train_images.append(i)\n",
    "                    else:\n",
    "                        print(\"Test Vid\" ,vid)\n",
    "                        X_test_frames.append(X_train_images_class[lower:upper])\n",
    "                    #print(\"Added frames\" , lower , \"to\" , upper)\n",
    "                    \n",
    "            print(\"Processed\",videos[i][j],\"of\",\"class\",classes[i])\n",
    "    return np.array(X_train_images,dtype=np.uint8),np.array(Y_train_images,dtype=np.uint8), np.array(X_test_images), np.array(Y_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = None\n",
    "X_test = None\n",
    "Y_train = None\n",
    "Y_test = None\n",
    "try:\n",
    "    X_train = np.load('../Numpy/End2End/X_train.npy')\n",
    "    Y_train = np.load('../Numpy/End2End/Y_train.npy')\n",
    "    X_test = np.load('../Numpy/End2End/X_test.npy')\n",
    "    Y_test = np.load('../Numpy/End2End/Y_test.npy')\n",
    "except FileNotFoundError:\n",
    "    X_train, Y_train, X_test, Y_test = build_dataset_end_to_end((172, 172))\n",
    "    np.save('../Numpy/End2End/X_train.npy', X_train)\n",
    "    np.save('../Numpy/End2End/Y_train.npy', Y_train)\n",
    "    np.save('../Numpy/End2End/X_test.npy', X_test)\n",
    "    np.save('../Numpy/End2End/Y_test.npy', Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((340, 40, 172, 172, 3), (22,), (340,), (22,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape,Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = permute(X_train, Y_train)\n",
    "Y_train = convert_to_one_hot(Y_train,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train2 = np.tile(Y_train, (40, 1, 1))\n",
    "Y_train2 = Y_train2.transpose(1, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 4, 5, 5, 6, 6, 7, 7, 7, 8, 8, 8])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 306 samples, validate on 34 samples\n",
      "Epoch 1/2\n",
      "306/306 [==============================] - 149s 486ms/step - loss: 0.8307 - Output_loss: 0.1621 - time_distributed_3_loss: 1.1144 - Output_acc: 0.9412 - time_distributed_3_acc: 0.5799 - val_loss: 0.5596 - val_Output_loss: 0.1095 - val_time_distributed_3_loss: 0.7502 - val_Output_acc: 0.9706 - val_time_distributed_3_acc: 0.8309\n",
      "Epoch 2/2\n",
      "306/306 [==============================] - 162s 530ms/step - loss: 0.7857 - Output_loss: 0.1339 - time_distributed_3_loss: 1.0864 - Output_acc: 0.9641 - time_distributed_3_acc: 0.5955 - val_loss: 0.5360 - val_Output_loss: 0.1041 - val_time_distributed_3_loss: 0.7198 - val_Output_acc: 0.9706 - val_time_distributed_3_acc: 0.8404\n"
     ]
    }
   ],
   "source": [
    "#filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_weights_only = False, save_best_only = False, mode='auto',period=1)\n",
    "dcnn = load_model('temp_11.h5')\n",
    "for i in range(1):\n",
    "    dcnn.fit(X_train, [Y_train,Y_train2] , batch_size=64, epochs=2 , validation_split=0.1)\n",
    "    dcnn.save('temp_'+ str(i+12) + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcnn = load_model('temp_12.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[3 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 0 0 0 0]\n",
      " [0 0 1 1 0 0 0 0 0]\n",
      " [0 0 0 0 3 0 0 0 0]\n",
      " [0 0 0 0 0 2 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0]\n",
      " [0 2 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 1 0 1 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "59.09090909090909"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(dcnn, X_test, Y_test, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-7ee3267ade4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "del X_train\n",
    "del Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_dataset(image_size, stride = 10, max_len = 40, \n",
    "                       video_path = '../UCF_Unseen/',\n",
    "                       image_path = '../UCF_Images/'):\n",
    "    \n",
    "    X_test_images = []\n",
    "    Y_test_images = []\n",
    "    \n",
    "    VIDEOS_DIR = video_path\n",
    "    IMAGES_DIR = image_path\n",
    "    classes = ['Kicking', 'Riding-Horse', 'Running', 'SkateBoarding', 'Swing-Bench', 'Lifting', 'Swing-Side', 'Walking', 'Golf-Swing']\n",
    "    videos = []\n",
    "    for x in classes:\n",
    "        videos.append(list(os.listdir(VIDEOS_DIR+x+'/')))\n",
    "    \n",
    "    for i in range(len(classes)):\n",
    "        cls = classes[i]\n",
    "        \n",
    "        for j in range(len(videos[i])):\n",
    "            vid = videos[i][j]\n",
    "            video_r = VIDEOS_DIR+cls+'/'+ vid +'/'\n",
    "            image_r = IMAGES_DIR+cls+'/'+ vid +'/'\n",
    "            filelist = sorted(list(os.listdir(image_r)))\n",
    "            X_train_images_class = []\n",
    "            for file in filelist:\n",
    "                if file.endswith(\".png\"):\n",
    "                    image = load_image(image_r+file,image_size)\n",
    "                    X_train_images_class.append(image)\n",
    "            X_train_images_class = np.array(X_train_images_class)        \n",
    "            X_test_frames = []                                \n",
    "            for k in range(0,len(X_train_images_class),stride):\n",
    "                lower = k\n",
    "                upper = min(len(X_train_images_class),k+max_len)\n",
    "                if upper == len(X_train_images_class):             \n",
    "                    X_test_frames.append(pad(X_train_images_class[lower:upper],max_len))\n",
    "                    X_test_images.append(np.array(X_test_frames))        \n",
    "                    Y_test_images.append(i)\n",
    "                    print(\"Padded frames\" , lower , \"to\" , upper)\n",
    "                    break\n",
    "                else:\n",
    "                    X_test_frames.append(X_train_images_class[lower:upper])\n",
    "                    print(\"Added frames\" , lower , \"to\" , upper)\n",
    "                    \n",
    "            print(\"Processed\",videos[i][j],\"of\",\"class\",classes[i])\n",
    "    return np.array(X_test_images), np.array(Y_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_full = None\n",
    "Y_test_full = None\n",
    "try:\n",
    "    X_test_full = np.load('../Numpy/End2End/X_test_full_training.npy')\n",
    "    Y_test_full = np.load('../Numpy/End2End/Y_test_full_training.npy')\n",
    "except FileNotFoundError:\n",
    "    X_test_full, Y_test_full = build_test_dataset((172,172),\n",
    "                                                  video_path='../Videos/',\n",
    "                                                  image_path='../Images/')\n",
    "    np.save('../Numpy/End2End/X_test_full_training.npy', X_test_full)\n",
    "    np.save('../Numpy/End2End/Y_test_full_training.npy', Y_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[16  0  0  0  0  0  0  0  0]\n",
      " [ 0  8  2  0  0  0  0  0  0]\n",
      " [ 0  1  8  0  0  0  0  0  0]\n",
      " [ 0  0  1  9  0  0  0  0  0]\n",
      " [ 0  0  0  0 14  3  0  0  0]\n",
      " [ 0  0  0  0  0  5  0  0  0]\n",
      " [ 0  0  0  0  0  3  8  0  0]\n",
      " [ 0  2  0  0  0  0  0 17  0]\n",
      " [ 0  0  0  0  0  1  0  1 12]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87.38738738738738"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(dcnn, X_test_full, Y_test_full, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_unseen = None\n",
    "Y_test_unseen = None\n",
    "try:\n",
    "    X_test_unseen = np.load('../Numpy/End2End/X_test_unseen.npy')\n",
    "    Y_test_unseen = np.load('../Numpy/End2End/Y_test_unseen.npy')\n",
    "except FileNotFoundError:\n",
    "    X_test_unseen, Y_test_unseen = build_test_dataset((172,172))\n",
    "    np.save('../Numpy/End2End/X_test_unseen.npy', X_test_unseen)\n",
    "    np.save('../Numpy/End2End/Y_test_unseen.npy', Y_test_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[3 0 0 0 0 1 0 0 0]\n",
      " [0 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0]\n",
      " [0 0 1 1 0 0 0 0 0]\n",
      " [0 0 0 0 1 2 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0]\n",
      " [0 0 0 0 0 0 0 3 0]\n",
      " [0 0 0 0 0 0 0 0 4]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68.18181818181817"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(dcnn, X_test_unseen, Y_test_unseen, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
