{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, Dropout, LSTM, BatchNormalization, Input,Activation, MaxPool2D, Flatten, Dense,TimeDistributed\n",
    "from keras.models import Model, load_model\n",
    "from keras import metrics \n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VIDEOS_DIR = './Videos/'\n",
    "IMAGES_DIR = './Images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kicking',\n",
       " 'Riding-Horse',\n",
       " 'Running',\n",
       " 'SkateBoarding',\n",
       " 'Swing-Bench',\n",
       " 'Lifting',\n",
       " 'Swing-Side',\n",
       " 'Walking',\n",
       " 'Golf-Swing']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = ['Kicking', 'Riding-Horse', 'Running', 'SkateBoarding', 'Swing-Bench', 'Lifting', 'Swing-Side', 'Walking', 'Golf-Swing']\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Golf-Swing': 8,\n",
       " 'Kicking': 0,\n",
       " 'Lifting': 5,\n",
       " 'Riding-Horse': 1,\n",
       " 'Running': 2,\n",
       " 'SkateBoarding': 3,\n",
       " 'Swing-Bench': 4,\n",
       " 'Swing-Side': 6,\n",
       " 'Walking': 7}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_to_index = {}\n",
    "for i in range(len(classes)):\n",
    "    class_to_index[classes[i]] = i\n",
    "class_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['006',\n",
       "  '017',\n",
       "  '003',\n",
       "  '016',\n",
       "  '009',\n",
       "  '013',\n",
       "  '005',\n",
       "  '012',\n",
       "  '010',\n",
       "  '015',\n",
       "  '014',\n",
       "  '007',\n",
       "  '004',\n",
       "  '011',\n",
       "  '002',\n",
       "  '001'],\n",
       " ['006', '003', '009', '005', '010', '007', '004', '002', '008', '001'],\n",
       " ['006', '009', '005', '010', '007', '004', '002', '008', '001'],\n",
       " ['006', '003', '009', '005', '010', '007', '004', '002', '008', '001'],\n",
       " ['006',\n",
       "  '017',\n",
       "  '003',\n",
       "  '016',\n",
       "  '009',\n",
       "  '013',\n",
       "  '005',\n",
       "  '012',\n",
       "  '010',\n",
       "  '015',\n",
       "  '014',\n",
       "  '007',\n",
       "  '004',\n",
       "  '011',\n",
       "  '002',\n",
       "  '008',\n",
       "  '001'],\n",
       " ['003', '005', '004', '002', '001'],\n",
       " ['006', '003', '009', '005', '010', '007', '004', '011', '002', '008', '001'],\n",
       " ['006',\n",
       "  '017',\n",
       "  '003',\n",
       "  '016',\n",
       "  '009',\n",
       "  '013',\n",
       "  '005',\n",
       "  '012',\n",
       "  '010',\n",
       "  '015',\n",
       "  '014',\n",
       "  '007',\n",
       "  '019',\n",
       "  '004',\n",
       "  '011',\n",
       "  '018',\n",
       "  '002',\n",
       "  '008',\n",
       "  '001'],\n",
       " ['006',\n",
       "  '003',\n",
       "  '009',\n",
       "  '013',\n",
       "  '005',\n",
       "  '012',\n",
       "  '010',\n",
       "  '014',\n",
       "  '007',\n",
       "  '004',\n",
       "  '011',\n",
       "  '002',\n",
       "  '008',\n",
       "  '001']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos = []\n",
    "for x in classes:\n",
    "    videos.append(list(os.listdir(VIDEOS_DIR+x+'/')))\n",
    "videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def permute(X,Y):\n",
    "    train_size = X.shape[0]\n",
    "    permutation_train = np.random.permutation(train_size)\n",
    "    X = X[permutation_train]\n",
    "    Y = Y[permutation_train]\n",
    "    return X,Y\n",
    "\n",
    "def load_image(path,image_size):\n",
    "    image = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, image_size)\n",
    "    return image\n",
    "\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)]\n",
    "    return Y\n",
    "\n",
    "def model_predict(model,images):\n",
    "    output = K.function([model.layers[0].input,K.learning_phase()],\n",
    "                        [model.layers[13].output])\n",
    "    return output([images,0])[0]\n",
    "\n",
    "def pad(X_cnn,max_len):\n",
    "    features_len = X_cnn.shape[1]\n",
    "    length = X_cnn.shape[0]\n",
    "    X_cnn = list(X_cnn)\n",
    "    pad_arr = [0 for i in range(features_len)]\n",
    "    for i in range(max_len-length):\n",
    "        X_cnn.append(pad_arr)\n",
    "    return np.array(X_cnn)\n",
    "\n",
    "def evaluate(X_test,Y_test,model):\n",
    "    count = 0\n",
    "    for i in range(len(X_test)):\n",
    "        pred = model.predict(X_test[i])\n",
    "        max_pred = [np.argmax(i) for i in pred]\n",
    "        counts = np.bincount(max_pred)\n",
    "        class_pred = np.argmax(counts)\n",
    "        #class_pred = max_pred\n",
    "        actual = np.argmax(Y_test[i])\n",
    "        #print(\"Max Preds time\", max_pred)\n",
    "        #print(\"Pred\",classes[class_pred],\"Actual\",classes[actual])\n",
    "        #print()\n",
    "        if class_pred == actual:\n",
    "            count += 1\n",
    "    return float(count)/float(len(Y_test)) * 100.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_dataset_for_lstm_strided(image_size, stride = 10, max_len = 40):\n",
    "    \n",
    "    model = load_model('models/Conv/17epochs_valacc_94.h5')\n",
    "    \n",
    "    X_train_images = []\n",
    "    Y_train_images = []\n",
    "    X_test_images = []\n",
    "    Y_test_images = []\n",
    "    \n",
    "    test_videos = [['002', '009'], ['005', '010'], ['007'], \\\n",
    "                   ['003'], ['006', '012'], ['004'], ['008'], ['004', '012'], ['001', '013']]\n",
    "    \n",
    "    for i in range(len(classes)):\n",
    "        cls = classes[i]\n",
    "        #test_video = random.randint(0,len(videos[i])-1)\n",
    "        test = test_videos[i] \n",
    "        #print(\"Selected Video for test is\",[videos[i][test_video] for test_video in test])\n",
    "\n",
    "        for j in range(len(videos[i])):\n",
    "            vid = videos[i][j]\n",
    "            video_r = VIDEOS_DIR+cls+'/'+ vid +'/'\n",
    "            image_r = IMAGES_DIR+cls+'/'+ vid +'/'\n",
    "            \n",
    "            filelist = sorted(list(os.listdir(image_r)))\n",
    "            X_train_images_class = []\n",
    "            \n",
    "            for file in filelist:\n",
    "                if file.endswith(\".png\"):\n",
    "                    image = load_image(image_r+file,image_size)\n",
    "                    X_train_images_class.append(image)\n",
    "            X_cnn = model_predict(model,np.array(X_train_images_class))\n",
    "            #print(X_cnn.shape)\n",
    "            \n",
    "            del X_train_images_class\n",
    "            X_test_frames = []                                \n",
    "            for k in range(0,X_cnn.shape[0],stride):\n",
    "                lower = k\n",
    "                upper = min(X_cnn.shape[0],k+max_len)\n",
    "                if upper == X_cnn.shape[0]:\n",
    "                    if vid not in test:                \n",
    "                        X_train_images.append(pad(X_cnn[lower:upper],max_len))\n",
    "                        Y_train_images.append(i)\n",
    "                    else:\n",
    "                        X_test_frames.append(pad(X_cnn[lower:upper],max_len))\n",
    "                        X_test_images.append(np.array(X_test_frames))        \n",
    "                        Y_test_images.append(i)\n",
    "                    #print(\"Padded frames\" , lower , \"to\" , upper)\n",
    "                    break\n",
    "                else:\n",
    "                    if vid not in test:                \n",
    "                        X_train_images.append(X_cnn[lower:upper])\n",
    "                        Y_train_images.append(i)\n",
    "                    else:\n",
    "                        X_test_frames.append(X_cnn[lower:upper])\n",
    "                    #print(\"Added frames\" , lower , \"to\" , upper)\n",
    "                    \n",
    "            print(\"Processed\",videos[i][j],\"of\",\"class\",classes[i])\n",
    "\n",
    "        #X_test_images.append(np.array(X_test_frames))        \n",
    "        #Y_test_images.append(i)\n",
    "    return X_train_images,Y_train_images,X_test_images,Y_test_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    X_input = Input(input_shape, name = \"Input\")\n",
    "    \n",
    "    X = BatchNormalization(name = 'BatchNorm_1')(X_input)\n",
    "    X = Conv2D(32, (7, 7), strides = (5, 5), name=\"Conv_1a\", padding=\"same\")(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(32, (3, 3), name = \"Conv_1b\", padding=\"same\")(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPool2D((2, 2), name = \"Pool_1\")(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    X = Conv2D(32, (3, 3), name =\"Conv_2\", padding = \"same\")(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPool2D((4, 4), name = \"Pool_2\")(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    X = Conv2D(8,(1,1), name='Conv_1x1')(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    return Model(X_input, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CNN_model(prev_model):\n",
    "    X = Dense(9,activation='softmax',name='final')(prev_model.output)\n",
    "    return Model(prev_model.input, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "BatchNorm_1 (BatchNormalizat (None, 172, 172, 3)       12        \n",
      "_________________________________________________________________\n",
      "Conv_1a (Conv2D)             (None, 35, 35, 32)        4736      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 35, 35, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_1b (Conv2D)             (None, 35, 35, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 35, 35, 32)        0         \n",
      "_________________________________________________________________\n",
      "Pool_1 (MaxPooling2D)        (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 17, 17, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "Pool_2 (MaxPooling2D)        (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "Conv_1x1 (Conv2D)            (None, 4, 4, 8)           264       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 23,508\n",
      "Trainable params: 23,502\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model((172, 172, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "BatchNorm_1 (BatchNormalizat (None, 172, 172, 3)       12        \n",
      "_________________________________________________________________\n",
      "Conv_1a (Conv2D)             (None, 35, 35, 32)        4736      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 35, 35, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_1b (Conv2D)             (None, 35, 35, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 35, 35, 32)        0         \n",
      "_________________________________________________________________\n",
      "Pool_1 (MaxPooling2D)        (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 17, 17, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "Pool_2 (MaxPooling2D)        (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "Conv_1x1 (Conv2D)            (None, 4, 4, 8)           264       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "final (Dense)                (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 24,669\n",
      "Trainable params: 24,663\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN_model(model)\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn.compile(loss='categorical_crossentropy', \n",
    "            metrics=['accuracy'], \n",
    "            optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_model(input_shape):\n",
    "    X_input = Input(input_shape)\n",
    "    X = LSTM(32, return_sequences=True)(X_input)\n",
    "    X = Dropout(0.3)(X)\n",
    "    X = LSTM(32, return_sequences=False)(X)\n",
    "    X = Dropout(0.3)(X)\n",
    "    X = Dense(9,activation='softmax')(X)\n",
    "    return Model(X_input, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 30, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30, 32)            20608     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 30, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 297       \n",
      "=================================================================\n",
      "Total params: 29,225\n",
      "Trainable params: 29,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn = rnn_model((30,128))\n",
    "rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn.compile(loss='categorical_crossentropy', \n",
    "            metrics=['accuracy'], \n",
    "            optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_loader(stride=10, max_len=40):\n",
    "    X_train = None\n",
    "    Y_train = None\n",
    "    X_test = None\n",
    "    Y_test = None\n",
    "    try:\n",
    "        X_train = np.load('Numpy/LSTM_Strided/train_X_'+str(stride)+'_'+str(max_len)+'.npy')\n",
    "        Y_train = np.load('Numpy/LSTM_Strided/train_Y_'+str(stride)+'_'+str(max_len)+'.npy')\n",
    "        X_test = np.load('Numpy/LSTM_Strided/test_X_'+str(stride)+'_'+str(max_len)+'.npy')\n",
    "        Y_test = np.load('Numpy/LSTM_Strided/test_Y_'+str(stride)+'_'+str(max_len)+'.npy')\n",
    "    except FileNotFoundError:\n",
    "        X_train,Y_train,X_test,Y_test = build_dataset_for_lstm_strided((172,172), stride, max_len)\n",
    "        X_train = np.array(X_train)\n",
    "        X_test = np.array(X_test)\n",
    "        Y_train = convert_to_one_hot(np.array(Y_train),9)\n",
    "        Y_test = convert_to_one_hot(np.array(Y_test),9)\n",
    "\n",
    "        np.save('Numpy/LSTM_Strided/train_X_'+str(stride)+'_'+str(max_len)+'.npy',X_train)\n",
    "        np.save('Numpy/LSTM_Strided/train_Y_'+str(stride)+'_'+str(max_len)+'.npy',Y_train)\n",
    "        np.save('Numpy/LSTM_Strided/test_X_'+str(stride)+'_'+str(max_len)+'.npy',X_test)\n",
    "        np.save('Numpy/LSTM_Strided/test_Y_'+str(stride)+'_'+str(max_len)+'.npy',Y_test)\n",
    "    \n",
    "    print(\"Training\")    \n",
    "    print(\"Shape X\",X_train.shape)\n",
    "    print(\"Shape Y\",Y_train.shape)\n",
    "    print()\n",
    "    print(\"Test\")\n",
    "    print(\"Shape X\",X_test.shape)\n",
    "    print(\"Shape Y\",Y_test.shape)\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 006 of class Kicking\n",
      "Processed 017 of class Kicking\n",
      "Processed 003 of class Kicking\n",
      "Processed 016 of class Kicking\n",
      "Processed 009 of class Kicking\n",
      "Processed 013 of class Kicking\n",
      "Processed 005 of class Kicking\n",
      "Processed 012 of class Kicking\n",
      "Processed 010 of class Kicking\n",
      "Processed 015 of class Kicking\n",
      "Processed 014 of class Kicking\n",
      "Processed 007 of class Kicking\n",
      "Processed 004 of class Kicking\n",
      "Processed 011 of class Kicking\n",
      "Processed 002 of class Kicking\n",
      "Processed 001 of class Kicking\n",
      "Processed 006 of class Riding-Horse\n",
      "Processed 003 of class Riding-Horse\n",
      "Processed 009 of class Riding-Horse\n",
      "Processed 005 of class Riding-Horse\n",
      "Processed 010 of class Riding-Horse\n",
      "Processed 007 of class Riding-Horse\n",
      "Processed 004 of class Riding-Horse\n",
      "Processed 002 of class Riding-Horse\n",
      "Processed 008 of class Riding-Horse\n",
      "Processed 001 of class Riding-Horse\n",
      "Processed 006 of class Running\n",
      "Processed 009 of class Running\n",
      "Processed 005 of class Running\n",
      "Processed 010 of class Running\n",
      "Processed 007 of class Running\n",
      "Processed 004 of class Running\n",
      "Processed 002 of class Running\n",
      "Processed 008 of class Running\n",
      "Processed 001 of class Running\n",
      "Processed 006 of class SkateBoarding\n",
      "Processed 003 of class SkateBoarding\n",
      "Processed 009 of class SkateBoarding\n",
      "Processed 005 of class SkateBoarding\n",
      "Processed 010 of class SkateBoarding\n",
      "Processed 007 of class SkateBoarding\n",
      "Processed 004 of class SkateBoarding\n",
      "Processed 002 of class SkateBoarding\n",
      "Processed 008 of class SkateBoarding\n",
      "Processed 001 of class SkateBoarding\n",
      "Processed 006 of class Swing-Bench\n",
      "Processed 017 of class Swing-Bench\n",
      "Processed 003 of class Swing-Bench\n",
      "Processed 016 of class Swing-Bench\n",
      "Processed 009 of class Swing-Bench\n",
      "Processed 013 of class Swing-Bench\n",
      "Processed 005 of class Swing-Bench\n",
      "Processed 012 of class Swing-Bench\n",
      "Processed 010 of class Swing-Bench\n",
      "Processed 015 of class Swing-Bench\n",
      "Processed 014 of class Swing-Bench\n",
      "Processed 007 of class Swing-Bench\n",
      "Processed 004 of class Swing-Bench\n",
      "Processed 011 of class Swing-Bench\n",
      "Processed 002 of class Swing-Bench\n",
      "Processed 008 of class Swing-Bench\n",
      "Processed 001 of class Swing-Bench\n",
      "Processed 003 of class Lifting\n",
      "Processed 005 of class Lifting\n",
      "Processed 004 of class Lifting\n",
      "Processed 002 of class Lifting\n",
      "Processed 001 of class Lifting\n",
      "Processed 006 of class Swing-Side\n",
      "Processed 003 of class Swing-Side\n",
      "Processed 009 of class Swing-Side\n",
      "Processed 005 of class Swing-Side\n",
      "Processed 010 of class Swing-Side\n",
      "Processed 007 of class Swing-Side\n",
      "Processed 004 of class Swing-Side\n",
      "Processed 011 of class Swing-Side\n",
      "Processed 002 of class Swing-Side\n",
      "Processed 008 of class Swing-Side\n",
      "Processed 001 of class Swing-Side\n",
      "Processed 006 of class Walking\n",
      "Processed 017 of class Walking\n",
      "Processed 003 of class Walking\n",
      "Processed 016 of class Walking\n",
      "Processed 009 of class Walking\n",
      "Processed 013 of class Walking\n",
      "Processed 005 of class Walking\n",
      "Processed 012 of class Walking\n",
      "Processed 010 of class Walking\n",
      "Processed 015 of class Walking\n",
      "Processed 014 of class Walking\n",
      "Processed 007 of class Walking\n",
      "Processed 019 of class Walking\n",
      "Processed 004 of class Walking\n",
      "Processed 011 of class Walking\n",
      "Processed 018 of class Walking\n",
      "Processed 002 of class Walking\n",
      "Processed 008 of class Walking\n",
      "Processed 001 of class Walking\n",
      "Processed 006 of class Golf-Swing\n",
      "Processed 003 of class Golf-Swing\n",
      "Processed 009 of class Golf-Swing\n",
      "Processed 013 of class Golf-Swing\n",
      "Processed 005 of class Golf-Swing\n",
      "Processed 012 of class Golf-Swing\n",
      "Processed 010 of class Golf-Swing\n",
      "Processed 014 of class Golf-Swing\n",
      "Processed 007 of class Golf-Swing\n",
      "Processed 004 of class Golf-Swing\n",
      "Processed 011 of class Golf-Swing\n",
      "Processed 002 of class Golf-Swing\n",
      "Processed 008 of class Golf-Swing\n",
      "Processed 001 of class Golf-Swing\n",
      "Training\n",
      "Shape X (620, 40, 128)\n",
      "Shape Y (620, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = data_loader(stride=5, max_len=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_rnn,Y_train_rnn = permute(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 40, 128),\n",
       " (1, 40, 128),\n",
       " (5, 40, 128),\n",
       " (1, 40, 128),\n",
       " (6, 40, 128),\n",
       " (7, 40, 128),\n",
       " (3, 40, 128),\n",
       " (3, 40, 128),\n",
       " (18, 40, 128),\n",
       " (1, 40, 128),\n",
       " (5, 40, 128),\n",
       " (14, 40, 128),\n",
       " (1, 40, 128),\n",
       " (5, 40, 128)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.shape for i in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search():\n",
    "    results = {}\n",
    "    histories = {}\n",
    "    strides = [5,7,11,13]\n",
    "    lengths = [20,30,40,50]\n",
    "    for stride in strides:\n",
    "        for length in lengths:\n",
    "            X_train, Y_train, X_test, Y_test = data_loader(stride, length)\n",
    "            X_train_rnn,Y_train_rnn = permute(X_train,Y_train)\n",
    "            \n",
    "            rnn = None\n",
    "            try:\n",
    "                rnn = load_model('models/LSTM_Strided/100ep_double_LSTM_dropout_'+ str(stride) + '_' + str(length)+'.h5')\n",
    "                histories[str(stride) + '_' + str(length)] = 'Trained'\n",
    "            except FileNotFoundError:\n",
    "                rnn = rnn_model((length,128))\n",
    "                rnn.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "                histories[str(stride) + '_' + str(length)] = rnn.fit(X_train_rnn, Y_train_rnn, epochs=100, batch_size = X_train_rnn.shape[0], validation_split=0.2)\n",
    "                rnn.save('models/LSTM_Strided/100ep_double_LSTM_dropout_'+ str(stride) + '_' + str(length)+'.h5')\n",
    "            results[str(stride) + '_' + str(length)] = evaluate(X_test, Y_test, rnn)\n",
    "    return results, histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Shape X (957, 20, 128)\n",
      "Shape Y (957, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (781, 30, 128)\n",
      "Shape Y (781, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (620, 40, 128)\n",
      "Shape Y (620, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (464, 50, 128)\n",
      "Shape Y (464, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (745, 20, 128)\n",
      "Shape Y (745, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (611, 30, 128)\n",
      "Shape Y (611, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (489, 40, 128)\n",
      "Shape Y (489, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (382, 50, 128)\n",
      "Shape Y (382, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (525, 20, 128)\n",
      "Shape Y (525, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (437, 30, 128)\n",
      "Shape Y (437, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (356, 40, 128)\n",
      "Shape Y (356, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (279, 50, 128)\n",
      "Shape Y (279, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (482, 20, 128)\n",
      "Shape Y (482, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (402, 30, 128)\n",
      "Shape Y (402, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (322, 40, 128)\n",
      "Shape Y (322, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (254, 50, 128)\n",
      "Shape Y (254, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-bd91ceb00af0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"results.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-bd91ceb00af0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mhist_pickle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistories\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mhist_pickle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist_pickle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "histories = None\n",
    "results = None\n",
    "try:\n",
    "    os.path.exists('results.pkl')\n",
    "    with open(\"results.pkl\", \"rb\") as f:\n",
    "        results = pickle.load(f)\n",
    "    with open(\"histories.pkl\", \"rb\") as f:\n",
    "        histories  = pickle.load(f)    \n",
    "except:    \n",
    "    results, histories = search()\n",
    "    with open(\"results.pkl\", \"wb\") as f:\n",
    "        pickle.dump(results, f)\n",
    "    with open(\"histories.pkl\", \"wb\") as f:\n",
    "        hist_pickle = {}\n",
    "        for key in histories:\n",
    "            hist_pickle[key] = histories[key].history\n",
    "        pickle.dump(hist_pickle,f)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'11_20': 78.57142857142857,\n",
       " '11_30': 64.28571428571429,\n",
       " '11_40': 71.42857142857143,\n",
       " '11_50': 71.42857142857143,\n",
       " '13_20': 78.57142857142857,\n",
       " '13_30': 64.28571428571429,\n",
       " '13_40': 64.28571428571429,\n",
       " '13_50': 64.28571428571429,\n",
       " '5_20': 71.42857142857143,\n",
       " '5_30': 57.14285714285714,\n",
       " '5_40': 71.42857142857143,\n",
       " '5_50': 64.28571428571429,\n",
       " '7_20': 78.57142857142857,\n",
       " '7_30': 57.14285714285714,\n",
       " '7_40': 57.14285714285714,\n",
       " '7_50': 71.42857142857143}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_test_dataset(image_size, stride = 10, max_len = 40):\n",
    "    \n",
    "    model = load_model('models/Conv/17epochs_valacc_94.h5')\n",
    "    \n",
    "    X_test_images = []\n",
    "    Y_test_images = []\n",
    "    \n",
    "    VIDEOS_DIR = './UCF_Unseen/'\n",
    "    IMAGES_DIR = './UCF_Images/'\n",
    "    \n",
    "    videos = []\n",
    "    for x in classes:\n",
    "        videos.append(list(os.listdir(VIDEOS_DIR+x+'/')))\n",
    "    \n",
    "    for i in range(len(classes)):\n",
    "        cls = classes[i]\n",
    "\n",
    "        for j in range(len(videos[i])):\n",
    "            vid = videos[i][j]\n",
    "            video_r = VIDEOS_DIR+cls+'/'+ vid +'/'\n",
    "            image_r = IMAGES_DIR+cls+'/'+ vid +'/'\n",
    "            \n",
    "            filelist = sorted(list(os.listdir(image_r)))\n",
    "            X_train_images_class = []\n",
    "            \n",
    "            for file in filelist:\n",
    "                if file.endswith(\".png\"):\n",
    "                    image = load_image(image_r+file,image_size)\n",
    "                    X_train_images_class.append(image)\n",
    "            X_cnn = model_predict(model,np.array(X_train_images_class))\n",
    "            print(X_cnn.shape)\n",
    "            \n",
    "            del X_train_images_class\n",
    "            X_test_frames = []                                \n",
    "            for k in range(0,X_cnn.shape[0],stride):\n",
    "                lower = k\n",
    "                upper = min(X_cnn.shape[0],k+max_len)\n",
    "                if upper == X_cnn.shape[0]:\n",
    "                    X_test_frames.append(pad(X_cnn[lower:upper],max_len))\n",
    "                    X_test_images.append(np.array(X_test_frames))        \n",
    "                    Y_test_images.append(i)\n",
    "                    print(\"Padded frames\" , lower , \"to\" , upper)\n",
    "                    break\n",
    "                else:\n",
    "                    X_test_frames.append(X_cnn[lower:upper])\n",
    "                    print(\"Added frames\" , lower , \"to\" , upper)\n",
    "                    \n",
    "            print(\"Processed\",videos[i][j],\"of\",\"class\",classes[i])\n",
    "\n",
    "    return X_test_images,Y_test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 128)\n",
      "Padded frames 0 to 22\n",
      "Processed 010 of class Kicking\n",
      "(23, 128)\n",
      "Padded frames 0 to 23\n",
      "Processed 006 of class Kicking\n",
      "(23, 128)\n",
      "Padded frames 0 to 23\n",
      "Processed 004 of class Kicking\n",
      "(20, 128)\n",
      "Padded frames 0 to 20\n",
      "Processed 008 of class Kicking\n",
      "(58, 128)\n",
      "Added frames 0 to 40\n",
      "Added frames 10 to 50\n",
      "Padded frames 20 to 58\n",
      "Processed 011 of class Riding-Horse\n",
      "(36, 128)\n",
      "Padded frames 0 to 36\n",
      "Processed 012 of class Riding-Horse\n",
      "(65, 128)\n",
      "Added frames 0 to 40\n",
      "Added frames 10 to 50\n",
      "Added frames 20 to 60\n",
      "Padded frames 30 to 65\n",
      "Processed 012 of class Running\n",
      "(70, 128)\n",
      "Added frames 0 to 40\n",
      "Added frames 10 to 50\n",
      "Added frames 20 to 60\n",
      "Padded frames 30 to 70\n",
      "Processed 011 of class SkateBoarding\n",
      "(70, 128)\n",
      "Added frames 0 to 40\n",
      "Added frames 10 to 50\n",
      "Added frames 20 to 60\n",
      "Padded frames 30 to 70\n",
      "Processed 012 of class SkateBoarding\n",
      "(50, 128)\n",
      "Added frames 0 to 40\n",
      "Padded frames 10 to 50\n",
      "Processed 018 of class Swing-Bench\n",
      "(50, 128)\n",
      "Added frames 0 to 40\n",
      "Padded frames 10 to 50\n",
      "Processed 020 of class Swing-Bench\n",
      "(50, 128)\n",
      "Added frames 0 to 40\n",
      "Padded frames 10 to 50\n",
      "Processed 019 of class Swing-Bench\n",
      "(127, 128)\n",
      "Added frames 0 to 40\n",
      "Added frames 10 to 50\n",
      "Added frames 20 to 60\n",
      "Added frames 30 to 70\n",
      "Added frames 40 to 80\n",
      "Added frames 50 to 90\n",
      "Added frames 60 to 100\n",
      "Added frames 70 to 110\n",
      "Added frames 80 to 120\n",
      "Padded frames 90 to 127\n",
      "Processed 006 of class Lifting\n",
      "(75, 128)\n",
      "Added frames 0 to 40\n",
      "Added frames 10 to 50\n",
      "Added frames 20 to 60\n",
      "Added frames 30 to 70\n",
      "Padded frames 40 to 75\n",
      "Processed 012 of class Swing-Side\n",
      "(7, 128)\n",
      "Padded frames 0 to 7\n",
      "Processed 013 of class Swing-Side\n",
      "(109, 128)\n",
      "Added frames 0 to 40\n",
      "Added frames 10 to 50\n",
      "Added frames 20 to 60\n",
      "Added frames 30 to 70\n",
      "Added frames 40 to 80\n",
      "Added frames 50 to 90\n",
      "Added frames 60 to 100\n",
      "Padded frames 70 to 109\n",
      "Processed 021 of class Walking\n",
      "(71, 128)\n",
      "Added frames 0 to 40\n",
      "Added frames 10 to 50\n",
      "Added frames 20 to 60\n",
      "Added frames 30 to 70\n",
      "Padded frames 40 to 71\n",
      "Processed 020 of class Walking\n",
      "(101, 128)\n",
      "Added frames 0 to 40\n",
      "Added frames 10 to 50\n",
      "Added frames 20 to 60\n",
      "Added frames 30 to 70\n",
      "Added frames 40 to 80\n",
      "Added frames 50 to 90\n",
      "Added frames 60 to 100\n",
      "Padded frames 70 to 101\n",
      "Processed 022 of class Walking\n",
      "(60, 128)\n",
      "Added frames 0 to 40\n",
      "Added frames 10 to 50\n",
      "Padded frames 20 to 60\n",
      "Processed 009 of class Golf-Swing\n",
      "(60, 128)\n",
      "Added frames 0 to 40\n",
      "Added frames 10 to 50\n",
      "Padded frames 20 to 60\n",
      "Processed 005 of class Golf-Swing\n",
      "(60, 128)\n",
      "Added frames 0 to 40\n",
      "Added frames 10 to 50\n",
      "Padded frames 20 to 60\n",
      "Processed 007 of class Golf-Swing\n",
      "(60, 128)\n",
      "Added frames 0 to 40\n",
      "Added frames 10 to 50\n",
      "Padded frames 20 to 60\n",
      "Processed 008 of class Golf-Swing\n"
     ]
    }
   ],
   "source": [
    "X_test,Y_test = build_test_dataset((172,172))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 40, 128),\n",
       " (1, 40, 128),\n",
       " (1, 40, 128),\n",
       " (1, 40, 128),\n",
       " (3, 40, 128),\n",
       " (1, 40, 128),\n",
       " (4, 40, 128),\n",
       " (4, 40, 128),\n",
       " (4, 40, 128),\n",
       " (2, 40, 128),\n",
       " (2, 40, 128),\n",
       " (2, 40, 128),\n",
       " (10, 40, 128),\n",
       " (5, 40, 128),\n",
       " (1, 40, 128),\n",
       " (8, 40, 128),\n",
       " (5, 40, 128),\n",
       " (8, 40, 128),\n",
       " (3, 40, 128),\n",
       " (3, 40, 128),\n",
       " (3, 40, 128),\n",
       " (3, 40, 128)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.array(X_test)\n",
    "[i.shape for i in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 9)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test = convert_to_one_hot(np.array(Y_test), 9)\n",
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Preds time [0]\n",
      "Pred Kicking Actual Kicking\n",
      "Max Preds time [0]\n",
      "Pred Kicking Actual Kicking\n",
      "Max Preds time [2]\n",
      "Pred Running Actual Kicking\n",
      "Max Preds time [7]\n",
      "Pred Walking Actual Kicking\n",
      "Max Preds time [1, 1, 1]\n",
      "Pred Riding-Horse Actual Riding-Horse\n",
      "Max Preds time [1]\n",
      "Pred Riding-Horse Actual Riding-Horse\n",
      "Max Preds time [8, 8, 8, 8]\n",
      "Pred Golf-Swing Actual Running\n",
      "Max Preds time [0, 3, 3, 3]\n",
      "Pred SkateBoarding Actual SkateBoarding\n",
      "Max Preds time [2, 2, 2, 2]\n",
      "Pred Running Actual SkateBoarding\n",
      "Max Preds time [4, 4]\n",
      "Pred Swing-Bench Actual Swing-Bench\n",
      "Max Preds time [4, 4]\n",
      "Pred Swing-Bench Actual Swing-Bench\n",
      "Max Preds time [4, 4]\n",
      "Pred Swing-Bench Actual Swing-Bench\n",
      "Max Preds time [5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "Pred Lifting Actual Lifting\n",
      "Max Preds time [6, 6, 6, 6, 6]\n",
      "Pred Swing-Side Actual Swing-Side\n",
      "Max Preds time [6]\n",
      "Pred Swing-Side Actual Swing-Side\n",
      "Max Preds time [7, 7, 7, 7, 7, 7, 7, 7]\n",
      "Pred Walking Actual Walking\n",
      "Max Preds time [7, 7, 7, 7, 7]\n",
      "Pred Walking Actual Walking\n",
      "Max Preds time [7, 7, 7, 7, 7, 7, 7, 7]\n",
      "Pred Walking Actual Walking\n",
      "Max Preds time [8, 8, 8]\n",
      "Pred Golf-Swing Actual Golf-Swing\n",
      "Max Preds time [8, 8, 8]\n",
      "Pred Golf-Swing Actual Golf-Swing\n",
      "Max Preds time [8, 8, 8]\n",
      "Pred Golf-Swing Actual Golf-Swing\n",
      "Max Preds time [8, 8, 8]\n",
      "Pred Golf-Swing Actual Golf-Swing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81.81818181818183"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(X_test,Y_test,rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
