{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, Dropout, LSTM, BatchNormalization, Input,Activation, MaxPool2D, Flatten, Dense,TimeDistributed\n",
    "from keras.models import Model, load_model\n",
    "from keras import metrics \n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VIDEOS_DIR = '../Videos/'\n",
    "IMAGES_DIR = '../Images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kicking',\n",
       " 'Riding-Horse',\n",
       " 'Running',\n",
       " 'SkateBoarding',\n",
       " 'Swing-Bench',\n",
       " 'Lifting',\n",
       " 'Swing-Side',\n",
       " 'Walking',\n",
       " 'Golf-Swing']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = ['Kicking', 'Riding-Horse', 'Running', 'SkateBoarding', 'Swing-Bench', 'Lifting', 'Swing-Side', 'Walking', 'Golf-Swing']\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Golf-Swing': 8,\n",
       " 'Kicking': 0,\n",
       " 'Lifting': 5,\n",
       " 'Riding-Horse': 1,\n",
       " 'Running': 2,\n",
       " 'SkateBoarding': 3,\n",
       " 'Swing-Bench': 4,\n",
       " 'Swing-Side': 6,\n",
       " 'Walking': 7}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_to_index = {}\n",
    "for i in range(len(classes)):\n",
    "    class_to_index[classes[i]] = i\n",
    "class_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['006',\n",
       "  '017',\n",
       "  '003',\n",
       "  '016',\n",
       "  '009',\n",
       "  '013',\n",
       "  '005',\n",
       "  '012',\n",
       "  '010',\n",
       "  '015',\n",
       "  '014',\n",
       "  '007',\n",
       "  '004',\n",
       "  '011',\n",
       "  '002',\n",
       "  '001'],\n",
       " ['006', '003', '009', '005', '010', '007', '004', '002', '008', '001'],\n",
       " ['006', '009', '005', '010', '007', '004', '002', '008', '001'],\n",
       " ['006', '003', '009', '005', '010', '007', '004', '002', '008', '001'],\n",
       " ['006',\n",
       "  '017',\n",
       "  '003',\n",
       "  '016',\n",
       "  '009',\n",
       "  '013',\n",
       "  '005',\n",
       "  '012',\n",
       "  '010',\n",
       "  '015',\n",
       "  '014',\n",
       "  '007',\n",
       "  '004',\n",
       "  '011',\n",
       "  '002',\n",
       "  '008',\n",
       "  '001'],\n",
       " ['003', '005', '004', '002', '001'],\n",
       " ['006', '003', '009', '005', '010', '007', '004', '011', '002', '008', '001'],\n",
       " ['006',\n",
       "  '017',\n",
       "  '003',\n",
       "  '016',\n",
       "  '009',\n",
       "  '013',\n",
       "  '005',\n",
       "  '012',\n",
       "  '010',\n",
       "  '015',\n",
       "  '014',\n",
       "  '007',\n",
       "  '019',\n",
       "  '004',\n",
       "  '011',\n",
       "  '018',\n",
       "  '002',\n",
       "  '008',\n",
       "  '001'],\n",
       " ['006',\n",
       "  '003',\n",
       "  '009',\n",
       "  '013',\n",
       "  '005',\n",
       "  '012',\n",
       "  '010',\n",
       "  '014',\n",
       "  '007',\n",
       "  '004',\n",
       "  '011',\n",
       "  '002',\n",
       "  '008',\n",
       "  '001']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos = []\n",
    "for x in classes:\n",
    "    videos.append(list(os.listdir(VIDEOS_DIR+x+'/')))\n",
    "videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def permute(X,Y):\n",
    "    train_size = X.shape[0]\n",
    "    permutation_train = np.random.permutation(train_size)\n",
    "    X = X[permutation_train]\n",
    "    Y = Y[permutation_train]\n",
    "    return X,Y\n",
    "\n",
    "def load_image(path,image_size):\n",
    "    image = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, image_size)\n",
    "    return image\n",
    "\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)]\n",
    "    return Y\n",
    "\n",
    "def model_predict(model,images):\n",
    "    output = K.function([model.layers[0].input,K.learning_phase()],\n",
    "                        [model.layers[13].output])\n",
    "    return output([images,0])[0]\n",
    "\n",
    "def pad(X_cnn,max_len):\n",
    "    features_len = X_cnn.shape[1]\n",
    "    length = X_cnn.shape[0]\n",
    "    X_cnn = list(X_cnn)\n",
    "    pad_arr = [0 for i in range(features_len)]\n",
    "    for i in range(max_len-length):\n",
    "        X_cnn.append(pad_arr)\n",
    "    return np.array(X_cnn)\n",
    "\n",
    "def evaluate(X_test,Y_test,model):\n",
    "    count = 0\n",
    "    for i in range(len(X_test)):\n",
    "        pred = model.predict(X_test[i])\n",
    "        max_pred = [np.argmax(i) for i in pred]\n",
    "        counts = np.bincount(max_pred)\n",
    "        class_pred = np.argmax(counts)\n",
    "        #class_pred = max_pred\n",
    "        actual = np.argmax(Y_test[i])\n",
    "        #print(\"Max Preds time\", max_pred)\n",
    "        #print(\"Pred\",classes[class_pred],\"Actual\",classes[actual])\n",
    "        #print()\n",
    "        if class_pred == actual:\n",
    "            count += 1\n",
    "    return float(count)/float(len(Y_test)) * 100.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_dataset_for_lstm_strided(image_size, stride = 10, max_len = 40):\n",
    "    \n",
    "    model = load_model('../models/Conv/17epochs_valacc_94.h5')\n",
    "    \n",
    "    X_train_images = []\n",
    "    Y_train_images = []\n",
    "    X_test_images = []\n",
    "    Y_test_images = []\n",
    "    \n",
    "    test_videos = [['002', '009'], ['005', '010'], ['007'], \\\n",
    "                   ['003'], ['006', '012'], ['004'], ['008'], ['004', '012'], ['001', '013']]\n",
    "    \n",
    "    for i in range(len(classes)):\n",
    "        cls = classes[i]\n",
    "        #test_video = random.randint(0,len(videos[i])-1)\n",
    "        test = test_videos[i] \n",
    "        #print(\"Selected Video for test is\",[videos[i][test_video] for test_video in test])\n",
    "\n",
    "        for j in range(len(videos[i])):\n",
    "            vid = videos[i][j]\n",
    "            video_r = VIDEOS_DIR+cls+'/'+ vid +'/'\n",
    "            image_r = IMAGES_DIR+cls+'/'+ vid +'/'\n",
    "            \n",
    "            filelist = sorted(list(os.listdir(image_r)))\n",
    "            X_train_images_class = []\n",
    "            \n",
    "            for file in filelist:\n",
    "                if file.endswith(\".png\"):\n",
    "                    image = load_image(image_r+file,image_size)\n",
    "                    X_train_images_class.append(image)\n",
    "            X_cnn = model_predict(model,np.array(X_train_images_class))\n",
    "            #print(X_cnn.shape)\n",
    "            \n",
    "            del X_train_images_class\n",
    "            X_test_frames = []                                \n",
    "            for k in range(0,X_cnn.shape[0],stride):\n",
    "                lower = k\n",
    "                upper = min(X_cnn.shape[0],k+max_len)\n",
    "                if upper == X_cnn.shape[0]:\n",
    "                    if vid not in test:                \n",
    "                        X_train_images.append(pad(X_cnn[lower:upper],max_len))\n",
    "                        Y_train_images.append(i)\n",
    "                    else:\n",
    "                        X_test_frames.append(pad(X_cnn[lower:upper],max_len))\n",
    "                        X_test_images.append(np.array(X_test_frames))        \n",
    "                        Y_test_images.append(i)\n",
    "                    #print(\"Padded frames\" , lower , \"to\" , upper)\n",
    "                    break\n",
    "                else:\n",
    "                    if vid not in test:                \n",
    "                        X_train_images.append(X_cnn[lower:upper])\n",
    "                        Y_train_images.append(i)\n",
    "                    else:\n",
    "                        X_test_frames.append(X_cnn[lower:upper])\n",
    "                    #print(\"Added frames\" , lower , \"to\" , upper)\n",
    "                    \n",
    "            print(\"Processed\",videos[i][j],\"of\",\"class\",classes[i])\n",
    "\n",
    "        #X_test_images.append(np.array(X_test_frames))        \n",
    "        #Y_test_images.append(i)\n",
    "    return X_train_images,Y_train_images,X_test_images,Y_test_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    X_input = Input(input_shape, name = \"Input\")\n",
    "    \n",
    "    X = BatchNormalization(name = 'BatchNorm_1')(X_input)\n",
    "    X = Conv2D(32, (7, 7), strides = (5, 5), name=\"Conv_1a\", padding=\"same\")(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(32, (3, 3), name = \"Conv_1b\", padding=\"same\")(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPool2D((2, 2), name = \"Pool_1\")(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    X = Conv2D(32, (3, 3), name =\"Conv_2\", padding = \"same\")(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPool2D((4, 4), name = \"Pool_2\")(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    X = Conv2D(8,(1,1), name='Conv_1x1')(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    return Model(X_input, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CNN_model(prev_model):\n",
    "    X = Dense(9,activation='softmax',name='final')(prev_model.output)\n",
    "    return Model(prev_model.input, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "BatchNorm_1 (BatchNormalizat (None, 172, 172, 3)       12        \n",
      "_________________________________________________________________\n",
      "Conv_1a (Conv2D)             (None, 35, 35, 32)        4736      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 35, 35, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_1b (Conv2D)             (None, 35, 35, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 35, 35, 32)        0         \n",
      "_________________________________________________________________\n",
      "Pool_1 (MaxPooling2D)        (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 17, 17, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "Pool_2 (MaxPooling2D)        (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "Conv_1x1 (Conv2D)            (None, 4, 4, 8)           264       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 23,508\n",
      "Trainable params: 23,502\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model((172, 172, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 172, 172, 3)       0         \n",
      "_________________________________________________________________\n",
      "BatchNorm_1 (BatchNormalizat (None, 172, 172, 3)       12        \n",
      "_________________________________________________________________\n",
      "Conv_1a (Conv2D)             (None, 35, 35, 32)        4736      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 35, 35, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_1b (Conv2D)             (None, 35, 35, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 35, 35, 32)        0         \n",
      "_________________________________________________________________\n",
      "Pool_1 (MaxPooling2D)        (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 17, 17, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "Pool_2 (MaxPooling2D)        (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "Conv_1x1 (Conv2D)            (None, 4, 4, 8)           264       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "final (Dense)                (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 24,669\n",
      "Trainable params: 24,663\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN_model(model)\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn.compile(loss='categorical_crossentropy', \n",
    "            metrics=['accuracy'], \n",
    "            optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_model(input_shape):\n",
    "    X_input = Input(input_shape)\n",
    "    X = LSTM(32, return_sequences=True)(X_input)\n",
    "    X = Dropout(0.3)(X)\n",
    "    X = LSTM(32, return_sequences=False)(X)\n",
    "    X = Dropout(0.3)(X)\n",
    "    X = Dense(9,activation='softmax')(X)\n",
    "    return Model(X_input, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 30, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30, 32)            20608     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 30, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 297       \n",
      "=================================================================\n",
      "Total params: 29,225\n",
      "Trainable params: 29,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn = rnn_model((30,128))\n",
    "rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn.compile(loss='categorical_crossentropy', \n",
    "            metrics=['accuracy'], \n",
    "            optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_loader(stride=10, max_len=40):\n",
    "    X_train = None\n",
    "    Y_train = None\n",
    "    X_test = None\n",
    "    Y_test = None\n",
    "    try:\n",
    "        X_train = np.load('../Numpy/LSTM_Strided/train_X_'+str(stride)+'_'+str(max_len)+'.npy')\n",
    "        Y_train = np.load('../Numpy/LSTM_Strided/train_Y_'+str(stride)+'_'+str(max_len)+'.npy')\n",
    "        X_test = np.load('../Numpy/LSTM_Strided/test_X_'+str(stride)+'_'+str(max_len)+'.npy')\n",
    "        Y_test = np.load('../Numpy/LSTM_Strided/test_Y_'+str(stride)+'_'+str(max_len)+'.npy')\n",
    "    except FileNotFoundError:\n",
    "        X_train,Y_train,X_test,Y_test = build_dataset_for_lstm_strided((172,172), stride, max_len)\n",
    "        X_train = np.array(X_train)\n",
    "        X_test = np.array(X_test)\n",
    "        Y_train = convert_to_one_hot(np.array(Y_train),9)\n",
    "        Y_test = convert_to_one_hot(np.array(Y_test),9)\n",
    "\n",
    "        np.save('../Numpy/LSTM_Strided/train_X_'+str(stride)+'_'+str(max_len)+'.npy',X_train)\n",
    "        np.save('../Numpy/LSTM_Strided/train_Y_'+str(stride)+'_'+str(max_len)+'.npy',Y_train)\n",
    "        np.save('../Numpy/LSTM_Strided/test_X_'+str(stride)+'_'+str(max_len)+'.npy',X_test)\n",
    "        np.save('../Numpy/LSTM_Strided/test_Y_'+str(stride)+'_'+str(max_len)+'.npy',Y_test)\n",
    "    \n",
    "    print(\"Training\")    \n",
    "    print(\"Shape X\",X_train.shape)\n",
    "    print(\"Shape Y\",Y_train.shape)\n",
    "    print()\n",
    "    print(\"Test\")\n",
    "    print(\"Shape X\",X_test.shape)\n",
    "    print(\"Shape Y\",Y_test.shape)\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Shape X (620, 40, 128)\n",
      "Shape Y (620, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = data_loader(stride=5, max_len=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_rnn,Y_train_rnn = permute(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 40, 128),\n",
       " (1, 40, 128),\n",
       " (5, 40, 128),\n",
       " (1, 40, 128),\n",
       " (6, 40, 128),\n",
       " (7, 40, 128),\n",
       " (3, 40, 128),\n",
       " (3, 40, 128),\n",
       " (18, 40, 128),\n",
       " (1, 40, 128),\n",
       " (5, 40, 128),\n",
       " (14, 40, 128),\n",
       " (1, 40, 128),\n",
       " (5, 40, 128)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.shape for i in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search():\n",
    "    results = {}\n",
    "    histories = {}\n",
    "    strides = [5,7,11,13]\n",
    "    lengths = [20,30,40,50]\n",
    "    for stride in strides:\n",
    "        for length in lengths:\n",
    "            X_train, Y_train, X_test, Y_test = data_loader(stride, length)\n",
    "            X_train_rnn,Y_train_rnn = permute(X_train,Y_train)\n",
    "            \n",
    "            rnn = None\n",
    "            try:\n",
    "                rnn = load_model('../models/LSTM_Strided/100ep_double_LSTM_dropout_'+ str(stride) + '_' + str(length)+'.h5')\n",
    "                histories[str(stride) + '_' + str(length)] = 'Trained'\n",
    "            except FileNotFoundError:\n",
    "                rnn = rnn_model((length,128))\n",
    "                rnn.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "                histories[str(stride) + '_' + str(length)] = rnn.fit(X_train_rnn, Y_train_rnn, epochs=100, batch_size = X_train_rnn.shape[0], validation_split=0.2)\n",
    "                rnn.save('../models/LSTM_Strided/100ep_double_LSTM_dropout_'+ str(stride) + '_' + str(length)+'.h5')\n",
    "            results[str(stride) + '_' + str(length)] = evaluate(X_test, Y_test, rnn)\n",
    "    return results, histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Shape X (957, 20, 128)\n",
      "Shape Y (957, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (781, 30, 128)\n",
      "Shape Y (781, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (620, 40, 128)\n",
      "Shape Y (620, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (464, 50, 128)\n",
      "Shape Y (464, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (745, 20, 128)\n",
      "Shape Y (745, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (611, 30, 128)\n",
      "Shape Y (611, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (489, 40, 128)\n",
      "Shape Y (489, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (382, 50, 128)\n",
      "Shape Y (382, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (525, 20, 128)\n",
      "Shape Y (525, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (437, 30, 128)\n",
      "Shape Y (437, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (356, 40, 128)\n",
      "Shape Y (356, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (279, 50, 128)\n",
      "Shape Y (279, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (482, 20, 128)\n",
      "Shape Y (482, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (402, 30, 128)\n",
      "Shape Y (402, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (322, 40, 128)\n",
      "Shape Y (322, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n",
      "Training\n",
      "Shape X (254, 50, 128)\n",
      "Shape Y (254, 9)\n",
      "\n",
      "Test\n",
      "Shape X (14,)\n",
      "Shape Y (14, 9)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-98ed73b042c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../histories.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mhistories\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-98ed73b042c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mhist_pickle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistories\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mhist_pickle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist_pickle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "histories = None\n",
    "results = None\n",
    "try:\n",
    "    with open(\"../results.pkl\", \"rb\") as f:\n",
    "        results = pickle.load(f)\n",
    "    with open(\"../histories.pkl\", \"rb\") as f:\n",
    "        histories  = pickle.load(f)    \n",
    "except:    \n",
    "    results, histories = search()\n",
    "    with open(\"../results.pkl\", \"wb\") as f:\n",
    "        pickle.dump(results, f)\n",
    "    with open(\"../histories.pkl\", \"wb\") as f:\n",
    "        hist_pickle = {}\n",
    "        for key in histories:\n",
    "            hist_pickle[key] = histories[key].history\n",
    "        pickle.dump(hist_pickle,f)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'11_20': 78.57142857142857,\n",
       " '11_30': 64.28571428571429,\n",
       " '11_40': 71.42857142857143,\n",
       " '11_50': 71.42857142857143,\n",
       " '13_20': 78.57142857142857,\n",
       " '13_30': 64.28571428571429,\n",
       " '13_40': 64.28571428571429,\n",
       " '13_50': 64.28571428571429,\n",
       " '5_20': 71.42857142857143,\n",
       " '5_30': 57.14285714285714,\n",
       " '5_40': 71.42857142857143,\n",
       " '5_50': 64.28571428571429,\n",
       " '7_20': 78.57142857142857,\n",
       " '7_30': 57.14285714285714,\n",
       " '7_40': 57.14285714285714,\n",
       " '7_50': 71.42857142857143}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_test_dataset(image_size, stride = 10, max_len = 40,videos_path = '../UCF_Unseen',\n",
    "                      images_path = '../UCF_Images'):\n",
    "    \n",
    "    model = load_model('../models/Conv/17epochs_valacc_94.h5')\n",
    "    \n",
    "    X_test_images = []\n",
    "    Y_test_images = []\n",
    "    \n",
    "    VIDEOS_DIR = videos_path\n",
    "    IMAGES_DIR = images_path\n",
    "    \n",
    "    videos = []\n",
    "    for x in classes:\n",
    "        videos.append(list(os.listdir(VIDEOS_DIR+x+'/')))\n",
    "    \n",
    "    for i in range(len(classes)):\n",
    "        cls = classes[i]\n",
    "\n",
    "        for j in range(len(videos[i])):\n",
    "            vid = videos[i][j]\n",
    "            video_r = VIDEOS_DIR+cls+'/'+ vid +'/'\n",
    "            image_r = IMAGES_DIR+cls+'/'+ vid +'/'\n",
    "            \n",
    "            filelist = sorted(list(os.listdir(image_r)))\n",
    "            X_train_images_class = []\n",
    "            \n",
    "            for file in filelist:\n",
    "                if file.endswith(\".png\"):\n",
    "                    image = load_image(image_r+file,image_size)\n",
    "                    X_train_images_class.append(image)\n",
    "            X_cnn = model_predict(model,np.array(X_train_images_class))\n",
    "            print(X_cnn.shape)\n",
    "            \n",
    "            del X_train_images_class\n",
    "            X_test_frames = []                                \n",
    "            for k in range(0,X_cnn.shape[0],stride):\n",
    "                lower = k\n",
    "                upper = min(X_cnn.shape[0],k+max_len)\n",
    "                if upper == X_cnn.shape[0]:\n",
    "                    X_test_frames.append(pad(X_cnn[lower:upper],max_len))\n",
    "                    X_test_images.append(np.array(X_test_frames))        \n",
    "                    Y_test_images.append(i)\n",
    "                    print(\"Padded frames\" , lower , \"to\" , upper)\n",
    "                    break\n",
    "                else:\n",
    "                    X_test_frames.append(X_cnn[lower:upper])\n",
    "                    print(\"Added frames\" , lower , \"to\" , upper)\n",
    "                    \n",
    "            print(\"Processed\",videos[i][j],\"of\",\"class\",classes[i])\n",
    "\n",
    "    return X_test_images,Y_test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test_unseen = None\n",
    "Y_test_unseen = None\n",
    "try:\n",
    "    X_test_unseen = np.load('../Numpy/Conv_LSTM/X_test_unseen.npy')\n",
    "    Y_test_unseen = np.load('../Numpy/Conv_LSTM/Y_test_unseen.npy')\n",
    "except FileNotFoundError:\n",
    "    X_test_unseen, Y_test_unseen = build_test_dataset((172,172))\n",
    "    np.save('../Numpy/Conv_LSTM/X_test_unseen.npy', X_test_unseen)\n",
    "    np.save('../Numpy/Conv_LSTM/Y_test_unseen.npy', Y_test_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 40, 128),\n",
       " (1, 40, 128),\n",
       " (1, 40, 128),\n",
       " (1, 40, 128),\n",
       " (1, 40, 128),\n",
       " (3, 40, 128),\n",
       " (4, 40, 128),\n",
       " (4, 40, 128),\n",
       " (4, 40, 128),\n",
       " (2, 40, 128),\n",
       " (2, 40, 128),\n",
       " (2, 40, 128),\n",
       " (10, 40, 128),\n",
       " (1, 40, 128),\n",
       " (5, 40, 128),\n",
       " (8, 40, 128),\n",
       " (5, 40, 128),\n",
       " (8, 40, 128),\n",
       " (3, 40, 128),\n",
       " (3, 40, 128),\n",
       " (3, 40, 128),\n",
       " (3, 40, 128)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_unseen = np.array(X_test_unseen)\n",
    "[i.shape for i in X_test_unseen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 9)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_unseen = convert_to_one_hot(np.array(Y_test_unseen), 9)\n",
    "Y_test_unseen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.27272727272727"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = load_model('../models/LSTM_Strided/500ep_valacc_100.h5')\n",
    "evaluate(X_test_unseen,Y_test_unseen,rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Full Dataset Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "mod = load_model('../models/LSTM_Strided/500ep_valacc_100.h5')\n",
    "res = evaluate(X_test_unseen,Y_test_unseen,mod)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
